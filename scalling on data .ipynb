{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aefec41d",
   "metadata": {},
   "source": [
    "## Differece in r2_score of  ANN Model, if we use :\n",
    "\n",
    "* StandardScaler on our data.\n",
    "\n",
    "* MinMaxScaler on our data. \n",
    "\n",
    "* Not use any scalling on our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17dadde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e8f78ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "940a51ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fetch_california_housing(as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "09b07f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.data\n",
    "df[data.target_names[0]] = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8e23ebfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedHouseVal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20635</th>\n",
       "      <td>1.5603</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.045455</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>845.0</td>\n",
       "      <td>2.560606</td>\n",
       "      <td>39.48</td>\n",
       "      <td>-121.09</td>\n",
       "      <td>0.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20636</th>\n",
       "      <td>2.5568</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.114035</td>\n",
       "      <td>1.315789</td>\n",
       "      <td>356.0</td>\n",
       "      <td>3.122807</td>\n",
       "      <td>39.49</td>\n",
       "      <td>-121.21</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20637</th>\n",
       "      <td>1.7000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.205543</td>\n",
       "      <td>1.120092</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>2.325635</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.22</td>\n",
       "      <td>0.923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20638</th>\n",
       "      <td>1.8672</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.329513</td>\n",
       "      <td>1.171920</td>\n",
       "      <td>741.0</td>\n",
       "      <td>2.123209</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.32</td>\n",
       "      <td>0.847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20639</th>\n",
       "      <td>2.3886</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.254717</td>\n",
       "      <td>1.162264</td>\n",
       "      <td>1387.0</td>\n",
       "      <td>2.616981</td>\n",
       "      <td>39.37</td>\n",
       "      <td>-121.24</td>\n",
       "      <td>0.894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20640 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0      8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1      8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2      7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3      5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4      3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "...       ...       ...       ...        ...         ...       ...       ...   \n",
       "20635  1.5603      25.0  5.045455   1.133333       845.0  2.560606     39.48   \n",
       "20636  2.5568      18.0  6.114035   1.315789       356.0  3.122807     39.49   \n",
       "20637  1.7000      17.0  5.205543   1.120092      1007.0  2.325635     39.43   \n",
       "20638  1.8672      18.0  5.329513   1.171920       741.0  2.123209     39.43   \n",
       "20639  2.3886      16.0  5.254717   1.162264      1387.0  2.616981     39.37   \n",
       "\n",
       "       Longitude  MedHouseVal  \n",
       "0        -122.23        4.526  \n",
       "1        -122.22        3.585  \n",
       "2        -122.24        3.521  \n",
       "3        -122.25        3.413  \n",
       "4        -122.25        3.422  \n",
       "...          ...          ...  \n",
       "20635    -121.09        0.781  \n",
       "20636    -121.21        0.771  \n",
       "20637    -121.22        0.923  \n",
       "20638    -121.32        0.847  \n",
       "20639    -121.24        0.894  \n",
       "\n",
       "[20640 rows x 9 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "abe926fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(columns='MedHouseVal')\n",
    "y = df['MedHouseVal']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3aa99d0",
   "metadata": {},
   "source": [
    "## ANN with StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4a7a0fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c400619f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "85c5c795",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ef431999",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "x_train = ss.fit_transform(x_train)\n",
    "x_test = ss.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c59fc13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LeakyReLU, ReLU, ELU, PReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "dca8a8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression = Sequential()\n",
    "regression.add(Dense(10, input_shape=(8,),activation='relu'))\n",
    "regression.add(Dense(10,activation='relu'))\n",
    "regression.add(Dense(10, activation='relu'))\n",
    "regression.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9e0f942b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_20 (Dense)            (None, 10)                90        \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 321\n",
      "Trainable params: 321\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "regression.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "bc596eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression.compile(optimizer='adam',loss=\"mse\",metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "1b8b1baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"mse\",\n",
    "    patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c3529d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.7498 - mse: 0.7498 - val_loss: 0.4260 - val_mse: 0.4260\n",
      "Epoch 2/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3962 - mse: 0.3962 - val_loss: 0.3878 - val_mse: 0.3878\n",
      "Epoch 3/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3720 - mse: 0.3720 - val_loss: 0.3711 - val_mse: 0.3711\n",
      "Epoch 4/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3544 - mse: 0.3544 - val_loss: 0.3521 - val_mse: 0.3521\n",
      "Epoch 5/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3443 - mse: 0.3443 - val_loss: 0.3527 - val_mse: 0.3527\n",
      "Epoch 6/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3365 - mse: 0.3365 - val_loss: 0.3384 - val_mse: 0.3384\n",
      "Epoch 7/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3310 - mse: 0.3310 - val_loss: 0.3407 - val_mse: 0.3407\n",
      "Epoch 8/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3271 - mse: 0.3271 - val_loss: 0.3331 - val_mse: 0.3331\n",
      "Epoch 9/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3289 - mse: 0.3289 - val_loss: 0.3357 - val_mse: 0.3357\n",
      "Epoch 10/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3199 - mse: 0.3199 - val_loss: 0.3316 - val_mse: 0.3316\n",
      "Epoch 11/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3181 - mse: 0.3181 - val_loss: 0.3280 - val_mse: 0.3280\n",
      "Epoch 12/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3162 - mse: 0.3162 - val_loss: 0.3318 - val_mse: 0.3318\n",
      "Epoch 13/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3164 - mse: 0.3164 - val_loss: 0.3189 - val_mse: 0.3189\n",
      "Epoch 14/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3111 - mse: 0.3111 - val_loss: 0.3318 - val_mse: 0.3318\n",
      "Epoch 15/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3108 - mse: 0.3108 - val_loss: 0.3151 - val_mse: 0.3151\n",
      "Epoch 16/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3050 - mse: 0.3050 - val_loss: 0.3242 - val_mse: 0.3242\n",
      "Epoch 17/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3027 - mse: 0.3027 - val_loss: 0.3199 - val_mse: 0.3199\n",
      "Epoch 18/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.2997 - mse: 0.2997 - val_loss: 0.3047 - val_mse: 0.3047\n",
      "Epoch 19/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.2982 - mse: 0.2982 - val_loss: 0.3134 - val_mse: 0.3134\n",
      "Epoch 20/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.2937 - mse: 0.2937 - val_loss: 0.3247 - val_mse: 0.3247\n",
      "Epoch 21/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.2933 - mse: 0.2933 - val_loss: 0.3179 - val_mse: 0.3179\n",
      "Epoch 22/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.2901 - mse: 0.2901 - val_loss: 0.3031 - val_mse: 0.3031\n",
      "Epoch 23/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.2892 - mse: 0.2892 - val_loss: 0.3271 - val_mse: 0.3271\n",
      "Epoch 24/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.2878 - mse: 0.2878 - val_loss: 0.2987 - val_mse: 0.2987\n",
      "Epoch 25/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.2877 - mse: 0.2877 - val_loss: 0.2958 - val_mse: 0.2958\n",
      "Epoch 26/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.2862 - mse: 0.2862 - val_loss: 0.3224 - val_mse: 0.3224\n",
      "Epoch 27/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.2830 - mse: 0.2830 - val_loss: 0.2996 - val_mse: 0.2996\n",
      "Epoch 28/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.2842 - mse: 0.2842 - val_loss: 0.2959 - val_mse: 0.2959\n",
      "Epoch 29/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.2845 - mse: 0.2845 - val_loss: 0.2872 - val_mse: 0.2872\n",
      "Epoch 30/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.2825 - mse: 0.2825 - val_loss: 0.3103 - val_mse: 0.3103\n",
      "Epoch 31/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.2830 - mse: 0.2830 - val_loss: 0.2855 - val_mse: 0.2855\n",
      "Epoch 32/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.2820 - mse: 0.2820 - val_loss: 0.2881 - val_mse: 0.2881\n",
      "Epoch 33/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.2806 - mse: 0.2806 - val_loss: 0.2937 - val_mse: 0.2937\n",
      "Epoch 34/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.2802 - mse: 0.2802 - val_loss: 0.2934 - val_mse: 0.2934\n",
      "Epoch 35/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.2784 - mse: 0.2784 - val_loss: 0.3108 - val_mse: 0.3108\n",
      "Epoch 36/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.2791 - mse: 0.2791 - val_loss: 0.3253 - val_mse: 0.3253\n",
      "Epoch 37/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.2787 - mse: 0.2787 - val_loss: 0.2951 - val_mse: 0.2951\n",
      "Epoch 38/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.2788 - mse: 0.2788 - val_loss: 0.2873 - val_mse: 0.2873\n",
      "Epoch 39/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.2796 - mse: 0.2796 - val_loss: 0.3021 - val_mse: 0.3021\n",
      "Epoch 40/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.2778 - mse: 0.2778 - val_loss: 0.2996 - val_mse: 0.2996\n",
      "Epoch 41/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.2780 - mse: 0.2780 - val_loss: 0.2905 - val_mse: 0.2905\n",
      "Epoch 42/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.2786 - mse: 0.2786 - val_loss: 0.2932 - val_mse: 0.2932\n",
      "Epoch 43/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.2757 - mse: 0.2757 - val_loss: 0.2856 - val_mse: 0.2856\n",
      "Epoch 44/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.2765 - mse: 0.2765 - val_loss: 0.2847 - val_mse: 0.2847\n",
      "Epoch 45/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.2756 - mse: 0.2756 - val_loss: 0.2946 - val_mse: 0.2946\n",
      "Epoch 46/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.2764 - mse: 0.2764 - val_loss: 0.2887 - val_mse: 0.2887\n",
      "Epoch 47/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.2755 - mse: 0.2755 - val_loss: 0.2918 - val_mse: 0.2918\n",
      "Epoch 48/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.2733 - mse: 0.2733 - val_loss: 0.2820 - val_mse: 0.2820\n",
      "Epoch 49/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.2742 - mse: 0.2742 - val_loss: 0.2806 - val_mse: 0.2806\n",
      "Epoch 50/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.2751 - mse: 0.2751 - val_loss: 0.2843 - val_mse: 0.2843\n",
      "Epoch 51/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.2707 - mse: 0.2707 - val_loss: 0.2924 - val_mse: 0.2924\n",
      "Epoch 52/100\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.2739 - mse: 0.2739 - val_loss: 0.2973 - val_mse: 0.2973\n",
      "Epoch 53/100\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.2725 - mse: 0.2725 - val_loss: 0.2864 - val_mse: 0.2864\n",
      "Epoch 54/100\n",
      "1652/1652 [==============================] - 7s 4ms/step - loss: 0.2708 - mse: 0.2708 - val_loss: 0.3329 - val_mse: 0.3329\n",
      "Epoch 55/100\n",
      "1652/1652 [==============================] - 8s 5ms/step - loss: 0.2709 - mse: 0.2709 - val_loss: 0.3060 - val_mse: 0.3060\n",
      "Epoch 56/100\n",
      "1652/1652 [==============================] - 7s 4ms/step - loss: 0.2721 - mse: 0.2721 - val_loss: 0.2812 - val_mse: 0.2812\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x269efe02888>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression.fit(x_train, y_train, validation_data=(x_test, y_test), batch_size=10,epochs=100,callbacks=early_stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b410440b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.573671 ],\n",
       "       [1.5140991],\n",
       "       [4.8436522],\n",
       "       ...,\n",
       "       [4.8839073],\n",
       "       [0.7137127],\n",
       "       [2.1245642]], dtype=float32)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds = regression.predict(x_test)\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "aeecf025",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4d6c8b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7854370112022594"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570b6678",
   "metadata": {},
   "source": [
    "## ANN without  StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a4a006f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b7b49aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression = Sequential()\n",
    "regression.add(Dense(10, input_shape=(8,),activation='relu'))\n",
    "regression.add(Dense(10,activation='relu'))\n",
    "regression.add(Dense(10, activation='relu'))\n",
    "regression.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5e46861d",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression.compile(optimizer='adam',loss=\"mse\",metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e6a702f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"mse\",\n",
    "    patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1b5d6571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1652/1652 [==============================] - 6s 3ms/step - loss: 524.9539 - mse: 524.9539 - val_loss: 1.7461 - val_mse: 1.7461\n",
      "Epoch 2/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 1.6014 - mse: 1.6014 - val_loss: 1.1163 - val_mse: 1.1163\n",
      "Epoch 3/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 1.7816 - mse: 1.7816 - val_loss: 0.9042 - val_mse: 0.9042\n",
      "Epoch 4/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 2.0795 - mse: 2.0795 - val_loss: 18.0646 - val_mse: 18.0646\n",
      "Epoch 5/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 5.0445 - mse: 5.0445 - val_loss: 0.7462 - val_mse: 0.7462\n",
      "Epoch 6/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 8.8156 - mse: 8.8156 - val_loss: 0.8424 - val_mse: 0.8424\n",
      "Epoch 7/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 3.5277 - mse: 3.5277 - val_loss: 0.7841 - val_mse: 0.7841\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26a85d43808>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression.fit(x_train, y_train, validation_data=(x_test, y_test), batch_size=10,epochs=100,callbacks=early_stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "bbce52fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = regression.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a0344ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4016325779564255"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd635cfb",
   "metadata": {},
   "source": [
    "## ANN with MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "13433f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2e811f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "489eea1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b7ccdee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = mm.fit_transform(x_train)\n",
    "x_test = mm.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ae8b9129",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression = Sequential()\n",
    "regression.add(Dense(10, input_shape=(8,),activation='relu'))\n",
    "regression.add(Dense(10,activation='relu'))\n",
    "regression.add(Dense(10, activation='relu'))\n",
    "\n",
    "regression.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b4240844",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression.compile(optimizer='adam',loss=\"mse\",metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "bf3af7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"mse\",\n",
    "    patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f1e90f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 1.0190 - mse: 1.0190 - val_loss: 0.6033 - val_mse: 0.6033\n",
      "Epoch 2/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.5747 - mse: 0.5747 - val_loss: 0.5662 - val_mse: 0.5662\n",
      "Epoch 3/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.5421 - mse: 0.5421 - val_loss: 0.5463 - val_mse: 0.5463\n",
      "Epoch 4/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.5114 - mse: 0.5114 - val_loss: 0.5088 - val_mse: 0.5088\n",
      "Epoch 5/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.4864 - mse: 0.4864 - val_loss: 0.4908 - val_mse: 0.4908\n",
      "Epoch 6/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.4710 - mse: 0.4710 - val_loss: 0.4865 - val_mse: 0.4865\n",
      "Epoch 7/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.4636 - mse: 0.4636 - val_loss: 0.4768 - val_mse: 0.4768\n",
      "Epoch 8/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.4565 - mse: 0.4565 - val_loss: 0.4789 - val_mse: 0.4789\n",
      "Epoch 9/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.4523 - mse: 0.4523 - val_loss: 0.4727 - val_mse: 0.4727\n",
      "Epoch 10/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.4468 - mse: 0.4468 - val_loss: 0.4722 - val_mse: 0.4722\n",
      "Epoch 11/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.4435 - mse: 0.4435 - val_loss: 0.4721 - val_mse: 0.4721\n",
      "Epoch 12/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.4401 - mse: 0.4401 - val_loss: 0.4660 - val_mse: 0.4660\n",
      "Epoch 13/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.4362 - mse: 0.4362 - val_loss: 0.4641 - val_mse: 0.4641\n",
      "Epoch 14/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.4321 - mse: 0.4321 - val_loss: 0.4731 - val_mse: 0.4731\n",
      "Epoch 15/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.4273 - mse: 0.4273 - val_loss: 0.4543 - val_mse: 0.4543\n",
      "Epoch 16/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.4196 - mse: 0.4196 - val_loss: 0.4554 - val_mse: 0.4554\n",
      "Epoch 17/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.4164 - mse: 0.4164 - val_loss: 0.4630 - val_mse: 0.4630\n",
      "Epoch 18/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.4110 - mse: 0.4110 - val_loss: 0.4568 - val_mse: 0.4568\n",
      "Epoch 19/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.4057 - mse: 0.4057 - val_loss: 0.4473 - val_mse: 0.4473\n",
      "Epoch 20/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.4018 - mse: 0.4018 - val_loss: 0.4369 - val_mse: 0.4369\n",
      "Epoch 21/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3996 - mse: 0.3996 - val_loss: 0.4433 - val_mse: 0.4433\n",
      "Epoch 22/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3945 - mse: 0.3945 - val_loss: 0.4329 - val_mse: 0.4329\n",
      "Epoch 23/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3896 - mse: 0.3896 - val_loss: 0.4651 - val_mse: 0.4651\n",
      "Epoch 24/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3879 - mse: 0.3879 - val_loss: 0.4267 - val_mse: 0.4267\n",
      "Epoch 25/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3866 - mse: 0.3866 - val_loss: 0.4310 - val_mse: 0.4310\n",
      "Epoch 26/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3843 - mse: 0.3843 - val_loss: 0.4282 - val_mse: 0.4282\n",
      "Epoch 27/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3818 - mse: 0.3818 - val_loss: 0.4277 - val_mse: 0.4277\n",
      "Epoch 28/100\n",
      "1652/1652 [==============================] - 8s 5ms/step - loss: 0.3806 - mse: 0.3806 - val_loss: 0.5341 - val_mse: 0.5341\n",
      "Epoch 29/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3786 - mse: 0.3786 - val_loss: 0.4167 - val_mse: 0.4167\n",
      "Epoch 30/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3751 - mse: 0.3751 - val_loss: 0.4502 - val_mse: 0.4502\n",
      "Epoch 31/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3747 - mse: 0.3747 - val_loss: 0.4166 - val_mse: 0.4166\n",
      "Epoch 32/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3729 - mse: 0.3729 - val_loss: 0.4173 - val_mse: 0.4173\n",
      "Epoch 33/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3700 - mse: 0.3700 - val_loss: 0.4271 - val_mse: 0.4271\n",
      "Epoch 34/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3710 - mse: 0.3710 - val_loss: 0.4726 - val_mse: 0.4726\n",
      "Epoch 35/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3670 - mse: 0.3670 - val_loss: 0.4097 - val_mse: 0.4097\n",
      "Epoch 36/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3647 - mse: 0.3647 - val_loss: 0.4118 - val_mse: 0.4118\n",
      "Epoch 37/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3656 - mse: 0.3656 - val_loss: 0.4140 - val_mse: 0.4140\n",
      "Epoch 38/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3628 - mse: 0.3628 - val_loss: 0.4055 - val_mse: 0.4055\n",
      "Epoch 39/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3605 - mse: 0.3605 - val_loss: 0.4082 - val_mse: 0.4082\n",
      "Epoch 40/100\n",
      "1652/1652 [==============================] - 6s 3ms/step - loss: 0.3584 - mse: 0.3584 - val_loss: 0.3953 - val_mse: 0.3953\n",
      "Epoch 41/100\n",
      "1652/1652 [==============================] - 6s 3ms/step - loss: 0.3588 - mse: 0.3588 - val_loss: 0.3987 - val_mse: 0.3987\n",
      "Epoch 42/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3550 - mse: 0.3550 - val_loss: 0.3921 - val_mse: 0.3921\n",
      "Epoch 43/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3590 - mse: 0.3590 - val_loss: 0.3866 - val_mse: 0.3866\n",
      "Epoch 44/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3548 - mse: 0.3548 - val_loss: 0.3867 - val_mse: 0.3867\n",
      "Epoch 45/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3512 - mse: 0.3512 - val_loss: 0.4252 - val_mse: 0.4252\n",
      "Epoch 46/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3544 - mse: 0.3544 - val_loss: 0.3808 - val_mse: 0.3808\n",
      "Epoch 47/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3493 - mse: 0.3493 - val_loss: 0.4070 - val_mse: 0.4070\n",
      "Epoch 48/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3505 - mse: 0.3505 - val_loss: 0.3828 - val_mse: 0.3828\n",
      "Epoch 49/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3500 - mse: 0.3500 - val_loss: 0.3948 - val_mse: 0.3948\n",
      "Epoch 50/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3475 - mse: 0.3475 - val_loss: 0.3779 - val_mse: 0.3779\n",
      "Epoch 51/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3484 - mse: 0.3484 - val_loss: 0.3850 - val_mse: 0.3850\n",
      "Epoch 52/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3458 - mse: 0.3458 - val_loss: 0.3678 - val_mse: 0.3678\n",
      "Epoch 53/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3461 - mse: 0.3461 - val_loss: 0.4065 - val_mse: 0.4065\n",
      "Epoch 54/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3476 - mse: 0.3476 - val_loss: 0.3746 - val_mse: 0.3746\n",
      "Epoch 55/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3438 - mse: 0.3438 - val_loss: 0.3928 - val_mse: 0.3928\n",
      "Epoch 56/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3426 - mse: 0.3426 - val_loss: 0.3729 - val_mse: 0.3729\n",
      "Epoch 57/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3420 - mse: 0.3420 - val_loss: 0.3894 - val_mse: 0.3894\n",
      "Epoch 58/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3413 - mse: 0.3413 - val_loss: 0.4247 - val_mse: 0.4247\n",
      "Epoch 59/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3359 - mse: 0.3359 - val_loss: 0.4130 - val_mse: 0.4130\n",
      "Epoch 60/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3354 - mse: 0.3354 - val_loss: 0.3597 - val_mse: 0.3597\n",
      "Epoch 61/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3311 - mse: 0.3311 - val_loss: 0.3492 - val_mse: 0.3492\n",
      "Epoch 62/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3317 - mse: 0.3317 - val_loss: 0.3571 - val_mse: 0.3571\n",
      "Epoch 63/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3308 - mse: 0.3308 - val_loss: 0.3508 - val_mse: 0.3508\n",
      "Epoch 64/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3272 - mse: 0.3272 - val_loss: 0.3463 - val_mse: 0.3463\n",
      "Epoch 65/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3274 - mse: 0.3274 - val_loss: 0.3529 - val_mse: 0.3529\n",
      "Epoch 66/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3270 - mse: 0.3270 - val_loss: 0.3412 - val_mse: 0.3412\n",
      "Epoch 67/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3290 - mse: 0.3290 - val_loss: 0.3526 - val_mse: 0.3526\n",
      "Epoch 68/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3263 - mse: 0.3263 - val_loss: 0.3744 - val_mse: 0.3744\n",
      "Epoch 69/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3251 - mse: 0.3251 - val_loss: 0.3491 - val_mse: 0.3491\n",
      "Epoch 70/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3239 - mse: 0.3239 - val_loss: 0.3548 - val_mse: 0.3548\n",
      "Epoch 71/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3237 - mse: 0.3237 - val_loss: 0.3490 - val_mse: 0.3490\n",
      "Epoch 72/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3235 - mse: 0.3235 - val_loss: 0.3465 - val_mse: 0.3465\n",
      "Epoch 73/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3195 - mse: 0.3195 - val_loss: 0.3491 - val_mse: 0.3491\n",
      "Epoch 74/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3201 - mse: 0.3201 - val_loss: 0.3518 - val_mse: 0.3518\n",
      "Epoch 75/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3180 - mse: 0.3180 - val_loss: 0.3356 - val_mse: 0.3356\n",
      "Epoch 76/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3210 - mse: 0.3210 - val_loss: 0.3273 - val_mse: 0.3273\n",
      "Epoch 77/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3230 - mse: 0.3230 - val_loss: 0.3306 - val_mse: 0.3306\n",
      "Epoch 78/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3157 - mse: 0.3157 - val_loss: 0.3268 - val_mse: 0.3268\n",
      "Epoch 79/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3186 - mse: 0.3186 - val_loss: 0.3367 - val_mse: 0.3367\n",
      "Epoch 80/100\n",
      "1652/1652 [==============================] - 4s 3ms/step - loss: 0.3169 - mse: 0.3169 - val_loss: 0.3335 - val_mse: 0.3335\n",
      "Epoch 81/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3170 - mse: 0.3170 - val_loss: 0.3247 - val_mse: 0.3247\n",
      "Epoch 82/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3163 - mse: 0.3163 - val_loss: 0.3232 - val_mse: 0.3232\n",
      "Epoch 83/100\n",
      "1652/1652 [==============================] - 5s 3ms/step - loss: 0.3164 - mse: 0.3164 - val_loss: 0.3469 - val_mse: 0.3469\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x269ef8c07c8>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression.fit(x_train, y_train, validation_data=(x_test, y_test), batch_size=10,epochs=100,callbacks=early_stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "80a58e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = regression.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e2483559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.735306701511156"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7659d5be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.050130309691103436"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.7854370112022594 - 0.735306701511156"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "d219804c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73.5306701511156"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.735306701511156*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "bd01e4ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78.54370112022593"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.7854370112022594*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "293f7434",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.16325779564255"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.4016325779564255*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "bd988c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.013030969110332"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "78.54370112022593 - 73.5306701511156"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "9f3937d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.36741235547305"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "73.5306701511156 - 40.16325779564255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "3f6e7509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.38044332458338"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "78.54370112022593 - 40.16325779564255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2f26d0",
   "metadata": {},
   "source": [
    "## conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c2878b",
   "metadata": {},
   "source": [
    "* r2_score of StandardScaler is `5.01% >` then r2_score of MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ffe024",
   "metadata": {},
   "source": [
    "* r2_score of MinMaxScaler is `33.3% >` then r2_score of without any scalling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5800ce",
   "metadata": {},
   "source": [
    "* r2_score of StandardScaler is `38.3% >` then r2_score of without any scalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c27335",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
